{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Artificial Neural Network for Customer Churn Prediction\n",
    "[Notebook from: http://youtube.com/c/ByteSizeDataScience]\n",
    "\n",
    "How to deal with overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import types\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "\n",
    "url = 'https://github.com/jacquesroy/byte-size-data-science/raw/master/data/customer_churn.csv'\n",
    "content = requests.get(url).content\n",
    "dataset = pd.read_csv(io.StringIO(content.decode('utf-8')))\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = dataset.iloc[:,2:17].values # Columns from Gender on\n",
    "y = dataset.iloc[:,1].values # CHURN column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding:\n",
    "- Categorical: Gender, Status, Car Owner, Paymethod, LocalBilltype, LongDistanceBilltype\n",
    "\n",
    "Other encoding could be used for some attributes. For example `onehotencoder` for Gender and Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data before split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# columns: 0 (Gender), 1(Status), 4 (Car owner), 10 (Payment method), 11 (LocalBillType), 12 (LongDistanceBillType)\n",
    "\n",
    "labelencoder_X_0 = LabelEncoder()\n",
    "X[:,0] = labelencoder_X_0.fit_transform(X[:,0])\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:,1] = labelencoder_X_1.fit_transform(X[:,1])\n",
    "labelencoder_X_4 = LabelEncoder()\n",
    "X[:,4] = labelencoder_X_4.fit_transform(X[:,4])\n",
    "labelencoder_X_10 = LabelEncoder()\n",
    "X[:,10] = labelencoder_X_10.fit_transform(X[:,10])\n",
    "labelencoder_X_11 = LabelEncoder()\n",
    "X[:,11] = labelencoder_X_11.fit_transform(X[:,11])\n",
    "labelencoder_X_12 = LabelEncoder()\n",
    "X[:,12] = labelencoder_X_12.fit_transform(X[:,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the answer column is \"T\" or \"F\", we have to encode it\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "# we need all the values in a standardized range \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see: https://keras.io\n",
    "import keras\n",
    "from keras.models import Sequential # to initialize NN\n",
    "from keras.layers import Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential model (most common in Keras)\n",
    "classifier = Sequential()\n",
    "\n",
    "# Create the first hidden layer\n",
    "classifier.add(Dense(8, activation='relu', input_shape=(15,))) # there are 15 attributes\n",
    "\n",
    "# Create the second hidden layer\n",
    "classifier.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Create the output layer\n",
    "classifier.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model content\n",
    "Show what the model is using the summary method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model visualization\n",
    "Another way to display the model.\n",
    "\n",
    "If you get an error, restart the kernel and re-execute all the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user --upgrade pydot\n",
    "!pip install --user --upgrade graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "from IPython.display import Image\n",
    "\n",
    "plot_model(classifier, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "Image('./model_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the neural network\n",
    "classifier.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (fit)\n",
    "# batch size: number of records used in each epoch\n",
    "# history = classifier.fit(X_train, y_train, batch_size=50, epochs=100, validation_split=0.2)\n",
    "history = classifier.fit(X_train, y_train, batch_size=50, epochs=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training progress\n",
    "In the previous cell, we passed the validation data so we can look at how the model fares at\n",
    "each step of the training.\n",
    "\n",
    "Instead of passing the test data, we could have split the training data into training and validation.\n",
    "We can plot the accuracy and loss results on a graph that would give us some indications on when \n",
    "the model becomes less efficient on the validation data.\n",
    "\n",
    "We use matplotlib to show these graphics. Note the line:\n",
    "\n",
    "`%matplotlib inline`\n",
    "\n",
    "This insures that the grahic is displayed in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the example code from the Keras documentation\n",
    "# See: https://keras.io/visualization/#training-history-visualization\n",
    "# Plot training & validation accuracy values\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing overfitting\n",
    "There are a few ways to reduce overfitting. It includes the use fo the `Dropout` layer and the `L1` and `L2` regularization functions.\n",
    "\n",
    "We use the same model but try to regulate overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout \n",
    "\n",
    "# Create a sequential model (most common in Keras)\n",
    "classifier = Sequential()\n",
    "\n",
    "# Create the first hidden layer\n",
    "classifier.add(Dense(8, activation='relu', input_shape=(15,))) # there are 15 attributes\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "# Create the second hidden layer\n",
    "classifier.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Create the output layer\n",
    "classifier.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the neural network\n",
    "classifier.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model (fit)\n",
    "# batch size: number of records used in each epoch\n",
    "history = classifier.fit(X_train, y_train, batch_size=50, epochs=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the example code from the Keras documentation\n",
    "# See: https://keras.io/visualization/#training-history-visualization\n",
    "# Plot training & validation accuracy values\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "# Create a sequential model (most common in Keras)\n",
    "classifier = Sequential()\n",
    "\n",
    "# Create the first hidden layer\n",
    "classifier.add(Dense(8, activation='relu', kernel_regularizer=regularizers.l2(0.03), input_shape=(15,))) # there are 15 attributes\n",
    "\n",
    "# Create the second hidden layer\n",
    "classifier.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Create the output layer\n",
    "classifier.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the neural network\n",
    "classifier.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model (fit)\n",
    "# batch size: number of records used in each epoch\n",
    "history = classifier.fit(X_train, y_train, batch_size=50, epochs=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the example code from the Keras documentation\n",
    "# See: https://keras.io/visualization/#training-history-visualization\n",
    "# Plot training & validation accuracy values\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
