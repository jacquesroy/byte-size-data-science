{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<IMG SRC=\"https://github.com/jacquesroy/byte-size-data-science/raw/master/images/Banner.png\" ALT=\"BSDS Banner\" WIDTH=1195 HEIGHT=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr><td>\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a></td><td>This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>.</td>\n",
    "    </tr>\n",
    "    <tr><td>Jacques Roy, Byte Size Data Science</td><td> </td></tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding and Preparation\n",
    "To understand data, we need to explore it.\n",
    "\n",
    "This adds to the following videos:\n",
    "- <a href=\"https://youtu.be/xSDP6u_Xqhc\">017-Spark Data Exploration</a>\n",
    "- <a href=\"https://youtu.be/AeeHapnLhyE\">018-Python Pandas Data Exploration</a>\n",
    "- <a href=\"https://youtu.be/qw4FtewQFZE\">032-JDBC Data Exploration</a>\n",
    "\n",
    "This time, we dig deeper and look at subjects such as:\n",
    "- Basic stats\n",
    "- Normalization\n",
    "- Reducing categorical choices\n",
    "- Correlation\n",
    "- Visualization \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 060-Data Understanding and Preparation\n",
    "Execute the next cell if you want to see the `Byte Size Data Science` youtube channel video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src=\"https://www.youtube.com/embed/vVX8GLEDwoY?rel=0&amp;controls=0&amp;showinfo=0\", width=560, height=315)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the appropriate libraries and set up needed connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ibm_db\n",
    "import ibm_db_dbi\n",
    "import math\n",
    "\n",
    "from ftplib import FTP\n",
    "import requests, zipfile, io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = {\n",
    "    'username': 'bluadmin',\n",
    "    'password': \"\"\"PASSWORD\"\"\",\n",
    "    'sg_service_url': 'https://sgmanager.ng.bluemix.net',\n",
    "    'database': 'BLUDB',\n",
    "    'host': 'dashdb-enterprise-. . . .bluemix.net',\n",
    "    'port': '50001',\n",
    "    'url': 'https://undefined'\n",
    "}\n",
    "schema=\"CHICAGO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsn = (\n",
    "    \"DRIVER={{IBM DB2 ODBC DRIVER}};\"\n",
    "    \"DATABASE={0};\"\n",
    "    \"HOSTNAME={1};\"\n",
    "    \"PORT={2};\"\n",
    "    \"PROTOCOL=TCPIP;\"\n",
    "    \"SECURITY=ssl;\"\n",
    "    \"UID={3};\"\n",
    "    \"PWD={4};\").format(credentials['database'], credentials['host'],\n",
    "                       credentials['port'], credentials['username'],\n",
    "                       credentials['password'])\n",
    "\n",
    "conn = ibm_db.connect(dsn, \"\", \"\")\n",
    "pconn = ibm_db_dbi.Connection(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chicago Accident data\n",
    "Just like in the previous videos mentioned above.\n",
    "\n",
    "This time, we assume that the data is in a database table as shown in video 059-CSV to DB\n",
    "\n",
    "The original data is at: https://github.com/jacquesroy/byte-size-data-science/raw/master/data/ChicagoTrafficCrashes20180917.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Staging table definition\n",
    "```\n",
    "CREATE TABLE CHICAGO.staging_ChicagoAccidents (\n",
    "  RD_NO                          VARCHAR(8) NOT NULL PRIMARY KEY,\n",
    "  CRASH_DATE_EST_I               CHAR(3),\n",
    "  CRASH_DATE                     TIMESTAMP,\n",
    "  POSTED_SPEED_LIMIT             INTEGER,\n",
    "  TRAFFIC_CONTROL_DEVICE         VARCHAR(23),\n",
    "  DEVICE_CONDITION               VARCHAR(24),\n",
    "  WEATHER_CONDITION              VARCHAR(22),\n",
    "  LIGHTING_CONDITION             VARCHAR(22),\n",
    "  FIRST_CRASH_TYPE               VARCHAR(28),\n",
    "  TRAFFICWAY_TYPE                VARCHAR(31),\n",
    "  LANE_CNT                       INTEGER,\n",
    "  ALIGNMENT                      VARCHAR(21),\n",
    "  ROADWAY_SURFACE_COND           VARCHAR(15),\n",
    "  ROAD_DEFECT                    VARCHAR(17),\n",
    "  REPORT_TYPE                    VARCHAR(26),\n",
    "  CRASH_TYPE                     VARCHAR(32),\n",
    "  INTERSECTION_RELATED_I         CHAR(3),\n",
    "  NOT_RIGHT_OF_WAY_I             CHAR(3),\n",
    "  HIT_AND_RUN_I                  CHAR(3),\n",
    "  DAMAGE                         VARCHAR(13),\n",
    "  DATE_POLICE_NOTIFIED           TIMESTAMP,\n",
    "  PRIM_CONTRIBUTORY_CAUSE        VARCHAR(80),\n",
    "  SEC_CONTRIBUTORY_CAUSE         VARCHAR(80),\n",
    "  STREET_NO                      INTEGER,\n",
    "  STREET_DIRECTION               CHAR(3),\n",
    "  STREET_NAME                    VARCHAR(31),\n",
    "  BEAT_OF_OCCURRENCE             INTEGER,\n",
    "  PHOTOS_TAKEN_I                 CHAR(3),\n",
    "  STATEMENTS_TAKEN_I             CHAR(3),\n",
    "  DOORING_I                      CHAR(3),\n",
    "  WORK_ZONE_I                    CHAR(3),\n",
    "  WORK_ZONE_TYPE                 VARCHAR(12),\n",
    "  WORKERS_PRESENT_I              CHAR(3),\n",
    "  NUM_UNITS                      INTEGER,\n",
    "  MOST_SEVERE_INJURY             VARCHAR(24),\n",
    "  INJURIES_TOTAL                 INTEGER,\n",
    "  INJURIES_FATAL                 INTEGER,\n",
    "  INJURIES_INCAPACITATING        INTEGER,\n",
    "  INJURIES_NON_INCAPACITATING    INTEGER,\n",
    "  INJURIES_REPORTED_NOT_EVIDENT  INTEGER,\n",
    "  INJURIES_NO_INDICATION         INTEGER,\n",
    "  INJURIES_UNKNOWN               INTEGER,\n",
    "  CRASH_HOUR                     INTEGER,\n",
    "  CRASH_DAY_OF_WEEK              INTEGER,\n",
    "  CRASH_MONTH                    INTEGER,\n",
    "  LATITUDE                       DOUBLE,\n",
    "  LONGITUDE                      DOUBLE \n",
    ") ORGANIZE BY ROW;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at distinct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT * FROM {0}.staging_ChicagoAccidents LIMIT 2\n",
    "\"\"\".format(schema)\n",
    "data_pd = pd.read_sql(sql, pconn)\n",
    "data_pd.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many non null values and distinct values in columns\n",
    "This is something we did in videos 17, 18, and 32. This time, we create an SQL statement programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the column names to create an SQL statement\n",
    "# Skip the location column. The fact it is a geometry causes issues with COUNT\n",
    "sql = \"SELECT \"\n",
    "for name in data_pd.columns.to_list() :\n",
    "    sql = sql + \"count({0}) {1}, count(distinct {0}) {2},\\n\".format(name, name + \"_count\", name + \"_distinct\")\n",
    "\n",
    "sql = sql[:-2] + \"\\n FROM {0}.staging_ChicagoAccidents\".format(schema)\n",
    "\n",
    "result_pd = pd.read_sql(sql, pconn)\n",
    "result_dict = result_pd.iloc[0].to_dict()\n",
    "\n",
    "for name in data_pd.columns.to_list() :\n",
    "    print(\"{0:30s}COUNT {1:8.0f}\\tDISTINCT {2:8.0f}\".format(name,result_dict[name + '_COUNT'],result_dict[name + '_DISTINCT'] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "Here, we are talking about relational database normal forms.\n",
    "\n",
    "We have multiple columns that are categorical. For example:\n",
    "- `TRAFFIC_CONTROL_DEVICE         VARCHAR(23)` - 15 unique values\n",
    "- `DEVICE_CONDITION               VARCHAR(24)` -  8 unique values\n",
    "- `WEATHER_CONDITION              VARCHAR(22)` -  9 unique values\n",
    "- `LIGHTING_CONDITION             VARCHAR(22)` -  6 unique values\n",
    "- `FIRST_CRASH_TYPE               VARCHAR(28)` - 15 unique values\n",
    "- `TRAFFICWAY_TYPE                VARCHAR(31)` - 11 unique values\n",
    "\n",
    "We can create small tables for each categorical column and popiulate them with their unique values.\n",
    "Then replace the string in the chicagoAccidents table with a 4-byte integer.\n",
    "\n",
    "For example, we would create a `TRAFFIC_CONTROL_DEVICE` table with two columns and 15 rows like:\n",
    "\n",
    "```\n",
    "ID  DESCRIPTION\n",
    "1\tLANE USE MARKING\n",
    "2\tNO CONTROLS\n",
    "3\tNO PASSING\n",
    "4\tOTHER\n",
    "5\tOTHER RAILROAD CROSSING\n",
    "```\n",
    "\n",
    "Then, the ChicagoAccidents column `TRAFFIC_CONTROL_DEVICE` woud be replace by `TRAFFIC_CONTROL_DEVICE_ID`.\n",
    "\n",
    "This saves us a lot of storage space and convert our text to a number that is more appropriate for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns that we want to convert into separate tables\n",
    "cat_columns = ['TRAFFIC_CONTROL_DEVICE','DEVICE_CONDITION','WEATHER_CONDITION','LIGHTING_CONDITION',\n",
    "           'FIRST_CRASH_TYPE','TRAFFICWAY_TYPE','ALIGNMENT','ROADWAY_SURFACE_COND','ROAD_DEFECT',\n",
    "           'REPORT_TYPE','CRASH_TYPE','DAMAGE','PRIM_CONTRIBUTORY_CAUSE','SEC_CONTRIBUTORY_CAUSE',\n",
    "           'WORK_ZONE_TYPE','MOST_SEVERE_INJURY'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_def = \"\"\"\n",
    "CREATE TABLE {0}.{1}_TABLE (\n",
    "    id          INT GENERATED ALWAYS AS IDENTITY\n",
    "                    (START WITH 1, INCREMENT BY 1),\n",
    "    description VARCHAR(80),\n",
    "    group_id    INT DEFAULT -1,\n",
    "\n",
    "    PRIMARY KEY(id)\n",
    ") ORGANIZE BY ROW;\n",
    "\"\"\"\n",
    "\n",
    "for col in cat_columns :\n",
    "    sql = table_def.format(schema,col)\n",
    "    cur = pconn.cursor()\n",
    "    cur.execute(sql)\n",
    "    print(\"Table {0}_TABLE created\".format(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_sql = \"\"\"\n",
    "  INSERT INTO {0}.{1}_TABLE(description)\n",
    "    SELECT distinct {1} AS description \n",
    "    FROM CHICAGO.staging_ChicagoAccidents\n",
    "\"\"\"\n",
    "for col in cat_columns :\n",
    "    sql = insert_sql.format(schema,col)\n",
    "    cur = pconn.cursor()\n",
    "    cur.execute(sql)\n",
    "    print(\"Table {0}_TABLE populated\".format(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing categorical choices\n",
    "The posted speed limit has 31 distinct values. We could reduce it in two ways:\n",
    "- Remove suspicious values from our analysis\n",
    "- Grouping the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at count per categorical value in each attribute\n",
    "We need to add a few columns that are numeric but still categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_cat_columns = ['POSTED_SPEED_LIMIT','LANE_CNT','NUM_UNITS', 'INJURIES_TOTAL',\n",
    "                     'CRASH_HOUR','CRASH_DAY_OF_WEEK','CRASH_MONTH']\n",
    "cat_all = cat_columns + other_cat_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the SQL statement\n",
    "We need to get all the counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same thing but with Quries to the table.\n",
    "# I have to build a series of SQL statements and do a UNION ALL on them\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT '{1}' COLNAME, attr.id COLVALUE, COUNT(*) VALCOUNT\n",
    "FROM {0}.staging_ChicagoAccidents acc, {0}.{1}_table attr\n",
    "WHERE acc.{1} = attr.description\n",
    "GROUP BY '{1}', attr.id \n",
    "\"\"\"\n",
    "\n",
    "query2 = \"\"\"\n",
    "SELECT '{1}' COLNAME, {1} COLVALUE, COUNT(*) VALCOUNT\n",
    "FROM {0}.staging_ChicagoAccidents acc\n",
    "GROUP BY '{1}', {1}\n",
    "\"\"\"\n",
    "\n",
    "sql = \"\"\n",
    "for name in cat_columns :\n",
    "    if (len(sql) > 0 ) :\n",
    "        sql = sql + \"UNION ALL\"\n",
    "    sql = sql + query.format(schema,name)\n",
    "for name in other_cat_columns :\n",
    "    sql = sql + \"UNION ALL\"\n",
    "    sql = sql + query2.format(schema,name)\n",
    "\n",
    "stats_pd = pd.read_sql(sql, pconn)\n",
    "print(\"Number of records: {0}\".format(stats_pd.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nb_rows = math.ceil(len(cat_all) / 2)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nb_rows, ncols=2)\n",
    "fig.set_figheight(75)\n",
    "fig.set_figwidth(15)\n",
    "for ix, ax in enumerate(axes.flatten()) :\n",
    "    if (ix < len(cat_all) ) :\n",
    "        tmp_pd = stats_pd[stats_pd['COLNAME'] == cat_all[ix]].sort_values(by=['COLVALUE'])\n",
    "        tmp_pd.plot.bar(ax=ax, x='COLVALUE', y='VALCOUNT',title=cat_all[ix], legend=False)\n",
    "        ax.set_xlabel('')\n",
    "    else:\n",
    "        fig.delaxes(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
