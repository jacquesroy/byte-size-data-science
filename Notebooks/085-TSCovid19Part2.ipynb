{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<IMG SRC=\"https://github.com/jacquesroy/byte-size-data-science/raw/master/images/Banner.png\" ALT=\"BSDS Banner\" WIDTH=1195 HEIGHT=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr><td>\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a></td><td>This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>.</td>\n",
    "    </tr>\n",
    "    <tr><td>Jacques Roy, Byte Size Data Science</td><td> </td></tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series with Covid Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youtube video related to this notebook\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src=\"https://www.youtube.com/embed/-OCj9L11y_0?rel=0&amp;controls=0&amp;showinfo=0\", width=560, height=315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries needed in the notebook\n",
    "import requests, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import dateutil.parser\n",
    "from io import StringIO\n",
    "import math\n",
    "\n",
    "# pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.patches lets us create colored patches, which we can use for legends in plots\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "Let's look at data from the CDC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library used to read datasets\n",
    "# https://github.com/xmunoz/sodapy\n",
    "!pip install sodapy 2>&1 >pipsodapy.txt\n",
    "\n",
    "from sodapy import Socrata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unauthenticated client only works with public data sets. Note 'None'\n",
    "# in place of application token, and no username or password:\n",
    "client = Socrata(\"data.cdc.gov\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get records from March 2021\n",
    "This API returns the data as character strings and limits queries to 10,000 records. We need to loop.\n",
    "\n",
    "We also select specific attributes, the same as in notebook 84."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "# If we wanted to do today:\n",
    "# We are using a fix date for future comparisons\n",
    "start_date = (date(2021,3,1)).strftime('%Y-%m-%d')\n",
    "where = \"submission_date >= '{}'\".format(start_date)\n",
    "select = \"submission_date,state,tot_cases,new_case,tot_death,new_death\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(client.get('9mfq-cb36', select=select,where=where, limit=10000))\n",
    "offset = 10000\n",
    "result = client.get('9mfq-cb36', offset=offset, select=select,where=where, limit=10000)\n",
    "while (len(result) > 0) :\n",
    "    data_df = data_df.append(pd.DataFrame(result))\n",
    "    offset += 10000\n",
    "    result = client.get('9mfq-cb36', offset=offset, select=select,where=where, limit=10000)\n",
    "\n",
    "print(\"Number of records: \" + str(data_df.shape[0]))\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to convert to the proper data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "need_types = {\n",
    "    'submission_date': 'datetime64[ns]', 'tot_cases': float,\n",
    "    'new_case': float, 'tot_death': float, 'new_death': float\n",
    "}\n",
    "data2_df = data_df.astype(need_types).sort_values(['submission_date', 'state'])\n",
    "\n",
    "data2_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### States population\n",
    "We use this so we can compare states.\n",
    "\n",
    "Amazingly difficult to find. I used a table found at: https://data.ers.usda.gov/reports.aspx?ID=17827\n",
    "\n",
    "Using the 2019 column. The important part is that we have a fix data point of population by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_pop = \"\"\"\n",
    "state,description,total\n",
    "US,United States,328239523\n",
    "AL,Alabama,4903185\n",
    "AK,Alaska,731545\n",
    "AZ,Arizona,7278717\n",
    "AR,Arkansas,3017804\n",
    "CA,California,39512223\n",
    "CO,Colorado,5758736\n",
    "CT,Connecticut,3565287\n",
    "DE,Delaware,973764\n",
    "DC,District of Columbia,705749\n",
    "FL,Florida,21477737\n",
    "GA,Georgia,10617423\n",
    "HI,Hawaii,1415872\n",
    "ID,Idaho,1787065\n",
    "IL,Illinois,12671821\n",
    "IN,Indiana,6732219\n",
    "IA,Iowa,3155070\n",
    "KS,Kansas,2913314\n",
    "KY,Kentucky,4467673\n",
    "LA,Louisiana,4648794\n",
    "ME,Maine,1344212\n",
    "MD,Maryland,6045680\n",
    "MA,Massachusetts,6892503\n",
    "MI,Michigan,9986857\n",
    "MN,Minnesota,5639632\n",
    "MS,Mississippi,2976149\n",
    "MO,Missouri,6137428\n",
    "MT,Montana,1068778\n",
    "NE,Nebraska,1934408\n",
    "NV,Nevada,3080156\n",
    "NH,New Hampshire,1359711\n",
    "NJ,New Jersey,8882190\n",
    "NM,New Mexico,2096829\n",
    "NY,New York,19453561\n",
    "NC,North Carolina,10488084\n",
    "ND,North Dakota,762062\n",
    "OH,Ohio,11689100\n",
    "OK,Oklahoma,3956971\n",
    "OR,Oregon,4217737\n",
    "PA,Pennsylvania,12801989\n",
    "RI,Rhode Island,1059361\n",
    "SC,South Carolina,5148714\n",
    "SD,South Dakota,884659\n",
    "TN,Tennessee,6829174\n",
    "TX,Texas,28995881\n",
    "UT,Utah,3205958\n",
    "VT,Vermont,623989\n",
    "VA,Virginia,8535519\n",
    "WA,Washington,7614893\n",
    "WV,West Virginia,1792147\n",
    "WI,Wisconsin,5822434\n",
    "WY,Wyoming,578759\n",
    "PR,Puerto Rico,3193694\n",
    "\"\"\"\n",
    "\n",
    "with StringIO(states_pop) as f:\n",
    "    pop_df = pd.read_csv(f)\n",
    "# pop_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot multiple states but use number of cases by 100K people\n",
    "Also plot the US to see which ones are above and below national average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'submission_date', 'state', 'tot_cases', 'new_case', 'tot_death', 'new_death'\n",
    "us_df = data2_df.groupby('submission_date').agg(np.sum)\n",
    "# us_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us population, create a divided for cases by 100K residents\n",
    "us_100k = pop_df[pop_df.state == 'US'].total.values[0] / 100000\n",
    "us_100k_df = us_df[['new_case']] / us_100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_list=['AZ','CA', 'FL', 'HI', 'MI', 'ND', 'NY', 'OR', 'SD', 'TX']\n",
    "\n",
    "states_df = data2_df[data2_df.state.isin(states_list)][['submission_date','state','new_case']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nb_rows = math.ceil(len(states_list) / 2)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nb_rows, ncols=2)\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(15)\n",
    "for ix, ax in enumerate(axes.flatten()) :\n",
    "    if (ix < len(states_list) ) :\n",
    "        div_val = pop_df[pop_df.state == states_list[ix]].total.values[0] / 100000\n",
    "        tmp_pd = states_df[states_df['state'] == states_list[ix]][['submission_date','new_case']]\n",
    "        tmp_pd.new_case = tmp_pd.new_case / div_val\n",
    "        tmp_pd.plot.line(ax=ax, x='submission_date',y='new_case', label= states_list[ix],\n",
    "                         title=states_list[ix] + \" New Cases\", legend=True)\n",
    "        us_100k_df.plot.line(ax=ax, y='new_case', label=\"US\", legend=True)\n",
    "        ax.set_xlabel('')\n",
    "    else:\n",
    "        fig.delaxes(ax) # Remove empty graph if any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oregon with moving average\n",
    "Use Pandas **`rolling`** capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "or_df = data2_df.loc[data2_df['state'] == 'OR']\n",
    "or_df.index = or_df.loc[:,'submission_date']\n",
    "\n",
    "or_df = or_df.assign(ma7=or_df['new_case'].rolling(7, min_periods=1).mean()) \n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "or_df['new_case'].plot.line(legend=True, grid=True)\n",
    "or_df['ma7'].plot.line(legend=True, grid=True)\n",
    "plt.title('Daily cases, Oregon')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different moving average\n",
    "ewm: exponential weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "or_df = or_df.assign(ewm = or_df['new_case'].ewm(halflife=4.0).mean())\n",
    "plt.figure(figsize=(18,6))\n",
    "or_df['new_case'].plot.line(legend=True, grid=True)\n",
    "or_df['ma7'].plot.line(legend=True, grid=True)\n",
    "or_df['ewm'].plot.line(legend=True, grid=True)\n",
    "plt.title('Daily cases, Oregon')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing States with moving averages\n",
    "MI ND OR and USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "for state in ['MI', 'ND', 'OR'] :\n",
    "    div_val = pop_df[pop_df.state == state]['total'].values[0] / 100000\n",
    "    tmp_pd = data2_df.loc[data2_df['state'] == state]\n",
    "    tmp_pd.index = tmp_pd['submission_date']\n",
    "    \n",
    "    #tmp_pd['new_case'] = tmp_pd['new_case'] / div_val # Causes warning\n",
    "    tmp_pd = tmp_pd.assign(normalized=tmp_pd['new_case'] / div_val)\n",
    "    \n",
    "    tmp_pd = tmp_pd.assign(ma7=tmp_pd['normalized'].rolling(7, min_periods=1).mean())\n",
    "    tmp_pd['ma7'].plot.line(label=state, legend=True, grid=True)\n",
    "    \n",
    "ma7 = us_100k_df['new_case'].rolling(7, min_periods=1).mean()\n",
    "ma7.plot.line(label='USA', legend=True, grid=True)\n",
    "plt.title('Daily cases moving average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS Analysis\n",
    "- Stationary\n",
    "- AR: Autoregression\n",
    "- MA: Moving average\n",
    "- ARMA: Autoregression moving average\n",
    "- ARIMA: Autoregressive integrates moving average\n",
    "\n",
    "\n",
    "https://www.statsmodels.org/stable/examples/index.html#time-series-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.graphics.tsaplots as sgt\n",
    "import statsmodels.tsa.stattools as sts\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for color display\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "def is_stationary(adf, name) :\n",
    "    if (adf[1] < 0.5) :\n",
    "        if (adf[0] < adf[4]['1%']) :\n",
    "            print('The {} time series is stationary within the 1% margin'.format(name))\n",
    "        elif (adf[0] < adf[4]['5%']) :\n",
    "            print('The {} time series is stationary within the 5% margin'.format(name))\n",
    "        else :\n",
    "            printmd(\"The {} time series is <span style='color:{}'>**NOT**</span> stationary\".format(name,'red'))\n",
    "    else :\n",
    "        printmd(\"The {} time series is <span style='color:{}'>**NOT**</span> stationary\".format(name,'red'))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = sts.adfuller(or_df.new_case)\n",
    "print('adf: {}\\npvalue: {}\\nusedlag: {}\\nnubs: {}'.format(adf[0],adf[1],adf[2],adf[3]))\n",
    "print('critical values: {}\\nicbest: {}'.format(adf[4],adf[5]))\n",
    "is_stationary(adf, 'total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA\n",
    "Predicting the next time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg, ar_select_order\n",
    "from statsmodels.tsa.api import acf, pacf, graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pmdarima 2>&1 >pmdarima.out\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from pmdarima.arima import auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_auto = auto_arima(or_df.new_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_auto.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
