{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<IMG SRC=\"https://github.com/jacquesroy/byte-size-data-science/raw/master/images/Banner.png\" ALT=\"BSDS Banner\" WIDTH=1195 HEIGHT=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logictic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src=\"https://www.youtube.com/embed/E4nhrtrGUWE?rel=0&amp;controls=0&amp;showinfo=0\", width=560, height=315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the appropriate libraries and set up needed connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests, zipfile, io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data\n",
    "<table style=\"width:50%;\" align=\"left\">\n",
    "    <tr><td style=\"text-align: left;vertical-align: top;\">\n",
    "Here we read the data we'll use to create and test<br/>\n",
    "our model. This data was mentioned in:<br/>\n",
    "        \n",
    "\"Data Science for business\"<br/>\n",
    "        \n",
    "Starting on page 104. I thought it would be<br/>\n",
    "interesting to see if we get similar results.\n",
    "        \n",
    "The data relates to breast cancer detection<br/>\n",
    "        between malign and benign tumors.\n",
    "        </td>\n",
    "<td><IMG SRC=\"https://miro.medium.com/max/500/1*dfkEYd_lCvR8XbpGufL-yw.jpeg\" ALT=\"Data Science for Business\" WIDTH=187 HEIGHT=283>\n",
    "    </td>\n",
    "    </tr>\n",
    "    </table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['ID','DIAGNOSIS',\n",
    "          'RADIUS_mean','TEXTURE_mean','PERIMETER_mean','AREA_mean','SMOOTHNESS_mean',\n",
    "          'COMPACTNESS_mean','CONCAVITY_mean','CONCAVEPOINTS_mean','SYMMETRY_mean', 'FRACTALDIMENSION_mean',\n",
    "          'RADIUS_se','TEXTURE_se','PERIMETER_se','AREA_se','SMOOTHNESS_se',\n",
    "          'COMPACTNESS_se','CONCAVITY_se','CONCAVEPOINTS_se','SYMMETRY_se', 'FRACTALDIMENSION_se',\n",
    "          'RADIUS_worst','TEXTURE_worst','PERIMETER_worst','AREA_worst','SMOOTHNESS_worst',\n",
    "          'COMPACTNESS_worst','CONCAVITY_worst','CONCAVEPOINTS_worst','SYMMETRY_worst', 'FRACTALDIMENSION_worst'\n",
    "         ]\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
    "\n",
    "stream = requests.get(url).content\n",
    "\n",
    "data_pd = pd.read_csv(io.StringIO(stream.decode('utf-8')),header=0,names=header)\n",
    "print(\"Number of records: {0}\".format(data_pd.shape[0]))\n",
    "data_pd.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data statistics. We see 20 of the 32 columns.\n",
    "# This gives us an idea of data distribution.\n",
    "data_pd.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model\n",
    "We are using the sklearn library to create our logistic regression model.<br/>\n",
    "We should be using a pipeline to automatically do data transformation. \n",
    "We are not using it here since we want to show the effect of the transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_pd.drop(['ID','DIAGNOSIS'], axis=1)\n",
    "y = data_pd['DIAGNOSIS']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "X_scaled_train = preprocessing.scale(X_train)\n",
    "X_scaled_test = preprocessing.scale(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at scaled data\n",
    "The scale preprocessing method centers the data to the mean and scale to the variance.\n",
    "\n",
    "We don't have the variance in the statistics provided by describe but we have the \n",
    "standard deviation that is the square root of the variance.\n",
    "\n",
    "If we did not scale the data, we would not be able to create a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_pd = pd.DataFrame(data=X_scaled_train,columns=header[2:])\n",
    "scaled_train_pd.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='lbfgs').fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at some of the model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result classes      : {0}\".format(clf.classes_))\n",
    "print(\"Number of iterations: {0}\".format(clf.n_iter_[0]))\n",
    "print(\"Intercept           : {0:8.6f}\".format(clf.intercept_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a few predictions\n",
    "Note that we are using scaled data just like when creting the model.<br/>\n",
    "This is where creating a pipeline would have been useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = clf.predict(X_scaled_test[5:8])\n",
    "predict_proba = clf.predict_proba(X_scaled_test[5:8])\n",
    "\n",
    "for i in range(3) :\n",
    "    print(\"Prediction: {0}, probability: {1:6.3f}, {2:6.3f}\".format(\n",
    "        predict[i], 100 * predict_proba[i][0],100 * predict_proba[i][1])\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How accurate is our model?\n",
    "The accuracy of the model is similar to the one mentioned in \"Data Science for Business\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = clf.score(X_scaled_test,y_test)\n",
    "print(\"Mean accuracy clf : {0}\".format(clf.score(X_scaled_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters importance\n",
    "Remember that the core of the logistic regression is a linear regression formula.<br/>\n",
    "We can retrive the weights (or coefficients) used for each attribute.\n",
    "\n",
    "The larger the absolute number is, the more impact an attribute has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip column names and weights\n",
    "x = zip(X_test.columns.tolist(),clf.coef_.tolist()[0])\n",
    "\n",
    "importance = pd.DataFrame(data=list(x),columns = ['NAME','WEIGHT'])\n",
    "print(\"Number of records: {0}\".format(importance.shape[0]))\n",
    "\n",
    "importance.reindex(importance.WEIGHT.abs().sort_values(ascending=False).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try multiple solvers\n",
    "If you are curious, you can execute this next cell to see that you may want to choose the \n",
    "algorithm to solve the linear regression formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "for solver in solvers :\n",
    "    clf = LogisticRegression(random_state=0,solver=solver).fit(X_scaled_train, y_train)\n",
    "    score = clf.score(X_scaled_test,y_test)\n",
    "    print(\"Score for solver {0}: {1}, iterations: {2}\".format(solver,score,clf.n_iter_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
